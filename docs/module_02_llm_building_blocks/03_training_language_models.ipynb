{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "750ebaba",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/raghavbali/mastering_llms_workshop_dhs2025/blob/main/docs/module_02_llm_building_blocks/03_training_language_models.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5969051-614a-4b50-9843-f8ba868c1b4e",
   "metadata": {
    "id": "e5969051-614a-4b50-9843-f8ba868c1b4e"
   },
   "source": [
    "# Training Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9004b66-6251-4d06-a157-19613f26c78a",
   "metadata": {
    "id": "b9004b66-6251-4d06-a157-19613f26c78a"
   },
   "source": [
    "## The 2-Step Training Paradigm\n",
    "\n",
    "Transformers are complex models built like LEGO blocks using multiple smart and specialized components.\n",
    "- A vanilla transformer model consists of separate stacks of encoders and decoders.\n",
    "- Each encoder block includes multi-head self-attention, enabling the model to capture relationships between tokens regardless of their positions.\n",
    "- Residual connections help maintain gradient flow, preventing the vanishing gradient problem.\n",
    "- Layer normalization ensures training stability, and feed-forward layers introduce non-linearity and learn complex token interactions.\n",
    "- Decoder blocks contain the same components but also include an encoder-decoder attention mechanism to incorporate context from the encoder.\n",
    "- The model uses embedding layers to convert tokens into a continuous latent space for contextual learning and positional encoding to preserve the order of tokens in the sequence\n",
    "\n",
    "<img src=\"../assets/02_training_setup_01.png\">\n",
    "\n",
    "> Source: Backcock, Bali et. al.\n",
    "\n",
    "The two-step **training paradigm** in transformer models is designed as follows:\n",
    "- **Pretraining** on large raw datasets like open-webtext, allowing the model to learn broad language patterns and concepts. This forms a strong foundation for various NLP tasks.\n",
    "- The second step, **fine-tuning**, uses task-specific datasets to tailor the model to particular tasks or domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cbce606-897b-404b-9dce-eba176de0bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.44.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DmM0R3F0resB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DmM0R3F0resB",
    "outputId": "d0547893-226d-4192-dc5c-6ba1cef3295d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install -U datasets==2.20.0 huggingface_hub==0.23.4 accelerate==0.33.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a7738a-9d8b-4f4f-9988-465840a1b853",
   "metadata": {},
   "source": [
    "## Imports and Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ba776a2-474e-470e-bd93-25cdff4779bf",
   "metadata": {
    "id": "3ba776a2-474e-470e-bd93-25cdff4779bf"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25829b27-9116-4b60-a801-b9072623f7a6",
   "metadata": {
    "id": "25829b27-9116-4b60-a801-b9072623f7a6"
   },
   "outputs": [],
   "source": [
    "def any_keyword_in_string(string, keywords):\n",
    "    for keyword in keywords:\n",
    "        if keyword in string:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72ddb702-d03f-4f41-a850-ba9ba03cfb32",
   "metadata": {
    "id": "72ddb702-d03f-4f41-a850-ba9ba03cfb32"
   },
   "outputs": [],
   "source": [
    "def filter_streaming_dataset(dataset, filters):\n",
    "    filtered_dict = defaultdict(list)\n",
    "    total = 0\n",
    "    for sample in tqdm(iter(dataset)):\n",
    "        total += 1\n",
    "        if any_keyword_in_string(sample[\"content\"], filters):\n",
    "            for k, v in sample.items():\n",
    "                filtered_dict[k].append(v)\n",
    "    print(f\"{len(filtered_dict['content'])/total:.2%} of data after filtering.\")\n",
    "    return Dataset.from_dict(filtered_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c876e7c5-4918-4e46-94b6-d3b021750c87",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adfa6f33-9f39-4520-b40f-2a127ab2b2b7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "adfa6f33-9f39-4520-b40f-2a127ab2b2b7",
    "outputId": "f2c47e49-54d6-4675-8533-2fedc53d811b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['code', 'repo_name', 'path', 'language', 'license', 'size'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['code', 'repo_name', 'path', 'language', 'license', 'size'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "# Try loading the original dataset\n",
    "# transformersbook/codeparrot\n",
    "ds_train = load_dataset(\"theothertom/codeparrot-python-only\", split=\"train\")\n",
    "ds_valid = load_dataset(\"theothertom/codeparrot-python-only\", split=\"validation\")\n",
    "\n",
    "\n",
    "raw_datasets = DatasetDict(\n",
    "    {\n",
    "        \"train\": ds_train.shuffle().select(range(5000)),\n",
    "        \"valid\": ds_valid.shuffle().select(range(500))\n",
    "    }\n",
    ")\n",
    "\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "mOf6u4c-2tDN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mOf6u4c-2tDN",
    "outputId": "759f438c-3cc9-4f1a-f707-5797b8b34150"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['code', 'repo_name', 'path', 'language', 'license', 'size'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "E36-Juun257J",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E36-Juun257J",
    "outputId": "dd0e1cfa-1dda-491b-cc2f-d906ac34f5f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1321"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train'][0]['size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7c8b6c3-923a-4d4d-9d64-5a71974d9f8b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b7c8b6c3-923a-4d4d-9d64-5a71974d9f8b",
    "outputId": "cb5e30a0-7a6e-4b82-d2b1-9ac6d672bf95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODE: from __future__ import absolute_import\n",
      "\n",
      "from sentry.testutils import AcceptanceTestCase\n",
      "\n",
      "\n",
      "class AuthTest(AcceptanceTestCase):\n",
      "    def enter_auth(self, username, password):\n",
      "        # disable captcha as\n",
      "REPO_NAME: mitsuhiko/sentry\n",
      "PATH: tests/acceptance/test_auth.py\n",
      "LANGUAGE: Python\n",
      "LICENSE: bsd-3-clause\n"
     ]
    }
   ],
   "source": [
    "for key in raw_datasets[\"train\"][0]:\n",
    "  if key != \"size\":\n",
    "    print(f\"{key.upper()}: {raw_datasets['train'][0][key][:200]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dde116-e0a7-4d30-afae-841579485ffe",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4ca8bea-7fd5-48b6-9096-a85e12c6606b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231,
     "referenced_widgets": [
      "317ecbc842c5458ea7675e1c97f68149",
      "09f9149fb6bc4c53b2f6ac57c86c14c8",
      "789275731c2842e49c055d3db7546f89",
      "0913f58d1a7e440391e78a305ddbb32c",
      "79bf942d8faa460ba2c502959126c9d5",
      "83c14e4935fa4d1b9649e5373c4ffcf8",
      "db34a8ecf03c48c9ab326d088d00b07f",
      "70793b6c6970454b86076b93ba7a10d6",
      "42e53f04791a4b6c9cbc2db7dd2e6410",
      "283cf507aa6c41ca9169d0f79567d7f0",
      "cca5c7b1b98944a996268654bfa49e75",
      "f0c2b937f3a4469da3d186c7ddac6b27",
      "b8008a46b40141ee8af1b6f52149153d",
      "98f3ad80834d4702bfb597e1fbf95f7d",
      "0a49075b707e4c23a928e84a56503d5d",
      "83fedea9186a47bdb952c4e5d96de5a6",
      "0dd83a9d954749d7a2f446c5b5de4104",
      "6e8a79a00eec4114a2cad20387397f00",
      "385e6c92d45c4f29adaf9c58e4a8569c",
      "bf6431b3449441caa8a792d7067a7008",
      "3415548c6f42401abfe03d65a1713120",
      "0d89f02eae944962b4e5461bca81dd32",
      "51c077e6b8c84049aa21fe81abb37d06",
      "40d41aa15a91421fbcd2fdae2f6e2d82",
      "824dbfc4b70e41d4a45253721e734c40",
      "751626205e8340eba9036ac65e63b9bf",
      "8e115728e5c84505ba9af973dd8449c8",
      "ccad0709604143a69d521d9a28187b83",
      "cb54d6fa85b9417cad3cf7106436cce1",
      "0a958d85fcad42f19d6e376a8126c97d",
      "e7fcc5a38e1b42268c814f06ec7a0893",
      "6c7cd1f5797e44e497ab36e42b552194",
      "ee64f2bc93d741a4b469c27eb416f693",
      "68256d242d1f419ca4946c403b4657a9",
      "ce9b163e28d04dedb4faa8cbb0400a08",
      "ea392581f1d349bcb660d93151e08a83",
      "f8a6b427aa2148beb967fd8fda1e5e4a",
      "01cd189318d44c808d4005ad4e7ba0ac",
      "dae69cf7ea224bd7b6434b8306cfa6d0",
      "3427fef8ad014c139c43f0a98ea28ff0",
      "cd59fc2e2e4a4177a2521ca23567034a",
      "3a8b99ac50df49f8912459e81da2cc4e",
      "6528195d227146ee8adb0263b2c6dbf9",
      "f9a95003eedf4821b3777e4aa6f72f20",
      "917a84d5785a482c8232954a9b485d79",
      "6ae47f35001841739ef59884287ae600",
      "bdf70388a9554068ab05f117e7dfb397",
      "aeb709d1fba24102aec5db69f376d32c",
      "5b7caf9883a04d2db22c9ba8d6c97f03",
      "e0033182de3041ceae428042add8c172",
      "b049874113f04806aceea8bb9fe07247",
      "1db313e172384116a1441fc2ffec778b",
      "118ee9ed427c436cb00e61a3277cfe26",
      "893f99b31abe42a1b13300bbbe9ce6c6",
      "4582af2157e64b11a7af171028f33b2d"
     ]
    },
    "id": "c4ca8bea-7fd5-48b6-9096-a85e12c6606b",
    "outputId": "8eb67c9a-2522-43fe-af6b-b00fe5ab8935"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs length: 4\n",
      "Input chunk lengths: [128, 128, 80, 82]\n",
      "Chunk mapping: [0, 0, 0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "context_length = 128\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"huggingface-course/code-search-net-tokenizer\")\n",
    "\n",
    "outputs = tokenizer(\n",
    "    raw_datasets[\"train\"][:2][\"code\"],\n",
    "    truncation=True,\n",
    "    max_length=context_length,\n",
    "    return_overflowing_tokens=True,\n",
    "    return_length=True,\n",
    ")\n",
    "\n",
    "print(f\"Input IDs length: {len(outputs['input_ids'])}\")\n",
    "print(f\"Input chunk lengths: {(outputs['length'])}\")\n",
    "print(f\"Chunk mapping: {outputs['overflow_to_sample_mapping']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "372ca044-4e4c-40c7-9a0d-f13d9288cf85",
   "metadata": {
    "id": "372ca044-4e4c-40c7-9a0d-f13d9288cf85"
   },
   "outputs": [],
   "source": [
    "def tokenize(element):\n",
    "    outputs = tokenizer(\n",
    "        element[\"code\"],\n",
    "        truncation=True,\n",
    "        max_length=context_length,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_length=True,\n",
    "    )\n",
    "    input_batch = []\n",
    "    for length, input_ids in zip(outputs[\"length\"], outputs[\"input_ids\"]):\n",
    "        if length == context_length:\n",
    "            input_batch.append(input_ids)\n",
    "    return {\"input_ids\": input_batch}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78bc233d-70c5-452b-9cc3-65b9f02d5f59",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260,
     "referenced_widgets": [
      "5e19026e1c084988945f0d3078bdecce",
      "80c5a4645cfd4391aaba7becd7be38b6",
      "21f6df1d31ce405c82ff4207dc1c6648",
      "8c9f2a83131f49efba2c7ea4ca2c15a3",
      "39a03aa0ac854709b627be2f09c75d41",
      "47567953ce604066a15546092b7ec307",
      "3e7904e44bd64be4a954fe64dce836c2",
      "530ae35e42864ea1b0712e2aa19c3754",
      "484e93035435426ca6e4a701833f9f76",
      "ab0071c69fb941c7bcb111ba6423b060",
      "7d795d211ea4493b9fcf60a9a036e36d",
      "f91cf1787a614c3097fda6fa58a2d1c0",
      "557b5d95050546628414a66e97e43541",
      "d2e67275336b4e5ba849ca3f21984808",
      "b7f1fba11bc549988261964b78178ac2",
      "64b75cadf221457ca71cb4342d36ed64",
      "1ae07f7127cd49b6b59ba15e3eda9ca8",
      "f2e7f2a1d5124cba9cacbd149c92c5fe",
      "a67a3f5dc82c43b78f08ca5732688add",
      "172ef46eadd0400a8091b393a587963f",
      "8b58d1ac39bc4f1b998ec118bc075944",
      "9cd8b942a18a4a04b1d39cb80067c272"
     ]
    },
    "id": "78bc233d-70c5-452b-9cc3-65b9f02d5f59",
    "outputId": "7c1a131c-0878-47ab-84a3-b88f1230147c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c64c9d67cc4a4e738e490fe23fe39783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58adf3867d1a4cdaa092cf0626e2e0e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids'],\n",
       "        num_rows: 79806\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['input_ids'],\n",
       "        num_rows: 9225\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize, batched=True, remove_columns=raw_datasets[\"train\"].column_names\n",
    ")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b170bfea-7442-4a08-9f4f-67738be5f909",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "145f4507-2932-4048-8f3b-1c5b131a22e1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "131ac72e48184281ad1aa6424fd22167",
      "ff39e549efb2444292efb580eccd7a24",
      "a2a2b22cf49741fb967167e8b0a42846",
      "d753ec3c2f7d441181eb434ba134bc6f",
      "1cefbd369d934311bb8290105f0d5daa",
      "aafda4ec4c4a4d27a61fabbacf2919d6",
      "0320f4d23a6b49d4be3aa8bef6d3d764",
      "621634e98509447987b38435f0e71443",
      "1fd90f7d6cd744ef99ed462e21de14d3",
      "c160ecce3f824f1385fb982b6a677e35",
      "4797a23929d24d2bb1204698f954cd65"
     ]
    },
    "id": "145f4507-2932-4048-8f3b-1c5b131a22e1",
    "outputId": "a6eb3d25-25f7-4c8c-972e-14fe054eed07"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, GPT2LMHeadModel, AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    vocab_size=len(tokenizer),\n",
    "    n_ctx=context_length,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4542cb7f-a8e5-4652-8469-907b0151a53b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4542cb7f-a8e5-4652-8469-907b0151a53b",
    "outputId": "09a04a4f-d0fb-407b-c2bd-c43f1cd320ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 size: 124.2M parameters\n"
     ]
    }
   ],
   "source": [
    "model = GPT2LMHeadModel(config)\n",
    "model_size = sum(t.numel() for t in model.parameters())\n",
    "print(f\"GPT-2 size: {model_size/1000**2:.1f}M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc86d5ac-84bd-4bf6-b848-1b26a6ee984c",
   "metadata": {
    "id": "cc86d5ac-84bd-4bf6-b848-1b26a6ee984c"
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d08ebf6c-c836-49d2-886b-3ae599dffb07",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d08ebf6c-c836-49d2-886b-3ae599dffb07",
    "outputId": "ecbec87c-364b-4b36-8d49-a10fcedf7c33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([5, 128])\n",
      "attention_mask shape: torch.Size([5, 128])\n",
      "labels shape: torch.Size([5, 128])\n"
     ]
    }
   ],
   "source": [
    "out = data_collator([tokenized_datasets[\"train\"][i] for i in range(5)])\n",
    "for key in out:\n",
    "    print(f\"{key} shape: {out[key].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34564b61-85f2-4d3d-84ae-19705d921eb3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "b4421efd70cc4732b8e7f3fae722589e",
      "110794d19fdb4d3ea2699fdffb2307e6",
      "d37dbcea9d0345219430ba45b496255e",
      "0d23eeab79eb4d3089236eb886f13f65",
      "9d8ec6ebcfd84c06b73a8920b0c6e083",
      "556041c723c24aac9c942fbf798f9305",
      "46fbf8e3ead043d485e3305b2e8a7e14",
      "a6328901d49846b4a5318505aad59196",
      "96b898dc816f4200843316c5f165ded6",
      "979a71fe6e1643d384661fa188d2add8",
      "c8353751fa0d4a9db15843e43dd2e465",
      "e4b6a6102a664912b6127123ee2bbc23",
      "1a2f518e562b4e82a68033cae238e457",
      "e0a950b6a9b9498e820104a28b97e2af",
      "6613f0c5aaf947b996f0013c423866de",
      "6b69bf16ca304410baa4e83d6488cd1a",
      "a032e33b9fb8413a80fcb875efea0cc0",
      "f10f3679b41b4a7a9fa35be87ddb2554",
      "1dd8884d9ec948a782059b02e7cb9420",
      "09af47906a38443fa4d395788ea5985e"
     ]
    },
    "id": "34564b61-85f2-4d3d-84ae-19705d921eb3",
    "outputId": "95ce105c-4cad-4b9e-e64e-6122f9ea4bbe"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "RA0WXAS44KMn",
   "metadata": {
    "id": "RA0WXAS44KMn"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323d09bc-b12c-41d7-8314-733b71976eb3",
   "metadata": {},
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1270680-66d4-4bbf-ad9d-3eda465cf5fb",
   "metadata": {
    "id": "c1270680-66d4-4bbf-ad9d-3eda465cf5fb"
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dcab00b-f0e5-4380-bc4d-0bf491fada73",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8dcab00b-f0e5-4380-bc4d-0bf491fada73",
    "outputId": "676d71bf-90f3-4fb1-f509-89f0ccbda6cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"codeparrot-ds\",\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    # evaluation_strategy=\"steps\",\n",
    "    eval_steps=5_000,\n",
    "    logging_steps=5_000,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.1,\n",
    "    warmup_steps=1_000,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    learning_rate=5e-4,\n",
    "    save_steps=5_000,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    "    report_to=None\n",
    "    # use_mps_device=False,\n",
    "    # use_cpu=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d499292b-29d4-41c0-bb73-5fd2ac53aa3e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d499292b-29d4-41c0-bb73-5fd2ac53aa3e",
    "outputId": "fa787363-479e-4aee-b8ba-daf7bcb353ef"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"valid\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cb39f30-72c3-4447-b860-d664784378c8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "id": "9cb39f30-72c3-4447-b860-d664784378c8",
    "outputId": "488ed3fc-0be3-4ff8-853f-19f23d67a88e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='311' max='311' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [311/311 05:37, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=311, training_loss=6.315891278135048, metrics={'train_runtime': 338.9317, 'train_samples_per_second': 235.463, 'train_steps_per_second': 0.918, 'total_flos': 5200756604928000.0, 'train_loss': 6.315891278135048, 'epoch': 0.9975942261427426})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upto 6mins on A40 GPU\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0889a00-8dd8-49a5-bb34-c2ef73b029ba",
   "metadata": {},
   "source": [
    "## Push to Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c73327-2571-4e98-b84d-c0aa04dc5c8b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "e7c73327-2571-4e98-b84d-c0aa04dc5c8b",
    "outputId": "dba1e986-8688-437a-e4bd-dc0577f284b0"
   },
   "outputs": [],
   "source": [
    "# trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25d4a9e-34d3-451b-852c-cca20cd288b6",
   "metadata": {},
   "source": [
    "## Let's Generate Some Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26ec4f91-a60b-4d0d-ac08-49e726c476b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291,
     "referenced_widgets": [
      "d4e93216ea694455985cce694ed18027",
      "9edd6b9bc9f640f7900561ed7b7e00c9",
      "7dba1a36707449c69c1c94b50e534035",
      "53ffff62458e4ab68b4593aa7f846251",
      "9ff7163c0a4c424495bcb4d8e703e058",
      "ae68872aec944b5ba843b0389b5026c9",
      "cf969c1a07164fbc90556890b5cb695e",
      "e39d2105294047749c56f5721d56f637",
      "de1922f8e7094e36b685da2f8d2b5410",
      "53d927a85ab3414580e935b23649f81e",
      "0ab7df7d09644437af0a89530d9bb068",
      "a844b003520045189241737e21cd018b",
      "38406ac3fec841e5a0b46e53704461ae",
      "9a02e6e31f7a4b5cb71d086de1c983c0",
      "8838ffeb2c04482482726a28c578ce05",
      "f041bc5dbbb04c4a96362d87e5cd3d9c",
      "62181b2b7937447f8d4587ec216c5e07",
      "21ee6f259c2241cd9f935fbed73716e4",
      "d7ea5195e9cd46af94cf371b4001b14c",
      "c0c7e2260c0b4966b9af4cda4efebfc2",
      "33835ff43834427195880dbbe24cc8c9",
      "dad43091b2864d6fbf8721c8307dd022",
      "939fab40189d4bcb8e7416638b0694ab",
      "6fa36b93b2f74caa9ccce45d6cbdfeb2",
      "d7f22b5a82144fb0834db4bf7f2ce8d4",
      "6b32e919f8b7477eb773d7d5e9fe15b5",
      "ebcbadf057804154ad63ac283cd3b1c1",
      "52b7104bb4d2415f9ad5f0690e285ee3",
      "b2fc0f2b5fc743fca62f58ff761b34a0",
      "ea2ed5d8499b4def96c6f7b7ba6ebea5",
      "327fd71f9fcc47c19d7dab2bd7aa2de1",
      "6a236cef81f54f1d99817df8e94f8c95",
      "6b8c9d16c36140e2ad8a18986856ed43",
      "0a04867a5ce8410eb3d5f66ac2527cca",
      "94786b625e39487d9df731e64a270af3",
      "43a1d946ed9e45dd8bcb8901660bd36b",
      "f9373fc0f4c94c048cefe8a1b0a734d6",
      "eadbd313b17e43a8a2239533d50ab438",
      "954f21d59b2e443ba40052f324c66c08",
      "12de770bd7b24d34a22a06448d8780cf",
      "476f610b450d4f7a9ee10e7bccd1af10",
      "a0dfc0bae32b4c6cb8488465dffbe7b2",
      "44cda4cf40f4484da6786fd8f75fe024",
      "900b620597a6402582bba22191c885b4",
      "918ce47ca2024d78b96a4e6ce40abe26",
      "136f5305efb54526b0d61128a9ab9f46",
      "55f4686d6384470b8d73e78909c0ac7c",
      "07739c0dd0d24365b3f3c01e80505e37",
      "8313188f6f7f4602ad2ccd0eb7e2a753",
      "c28e088df5df4ab5ba6b5c1f1f775353",
      "7a30eb85070f4ca3b66adfd01c600e46",
      "ebf32e642bb14e85846d5577ec78a96a",
      "7f97c685c0e94865b3e7fb4ce91d0d6a",
      "535f10c81b0747bbbd1ee87a04875c51",
      "41612dd7e20d452289e59f7699e85208",
      "d54718b8b4d64a4c98422e1ac2a441f3",
      "d9f09e56acba4a96b5c392fdd678e83b",
      "0d16a830abc147aaa0b51476ed6a7c72",
      "1971fca19e574d93bcfa02fd29940825",
      "7f50377147eb40ddab9ec71c87ac0cb8",
      "bb87380f2fbe443b8d50b8303277c806",
      "98741e7a3e4741a1a1236a2270f542e8",
      "1a0f1c17986649f8933fe0b3e53df588",
      "c246d98446e5483b85cb4184a9a49719",
      "0b8ec6b13e804f3fb996c5071837e599",
      "be76ccf807234589836790aa6be9d74f",
      "19fbe0e5372949c6a9e54ef32dceabb8",
      "d24a9da1d5bd463db9f251da144fe0e2",
      "6bb1fe2053294b8fa10edf1de8abeab8",
      "0ad613370d6947c3bf1812e39ffdffa5",
      "d193ffe5c74b4fb6aba54766767f8047",
      "846f3e7ace884b15a483d8170886c597",
      "6307d06620b748c48677598837e1e05b",
      "54709e818dd24c87b8895fde2b667ba6",
      "f4b3766e2b624326a852a25f2d26612b",
      "d13f07d6d58e4961aaa613d88c5205c4",
      "8364c99e2cac40dfa5d9f10f3efde426",
      "b231e26c709d4cbebb0730be85a9c601",
      "22c9e6d1a8dc42f49638400efb4ea218",
      "5b048cc1fd154de6b28a01e270e816d4",
      "7031d8e0dc6446598163f23ae3137414",
      "aee0e3c14dd648d6b2110aeba67672c3",
      "d70e751b2aca458993f80a4a01e6b737",
      "d72128eb6f804797a583f7e68c539499",
      "60e6886243ec4e6b96e82332689382e0",
      "678fe4abc8b24c10b7d2797442c75e0a",
      "1aec840529dd43d38731d4820d2f1267",
      "e3b504807afb4022abb0f1763e2fef11"
     ]
    },
    "id": "26ec4f91-a60b-4d0d-ac08-49e726c476b1",
    "outputId": "b46ba037-9205-4fe1-cc90-44cace0b397a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb545bdecb3a4b658c911bd12cee65da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/871 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b281e4dc7c84b4c8c97bbf56d35f2cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/497M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9abc29957bb34262925e91fb0f04be6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "pipe = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=\"raghavbali/codeparrot-ds\", \n",
    "    tokenizer=\"huggingface-course/code-search-net-tokenizer\",\n",
    "    device=device,\n",
    "    temperature=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1287052-28b8-4d08-8363-e0116cfcba3d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e1287052-28b8-4d08-8363-e0116cfcba3d",
    "outputId": "3eb9543e-4717-474b-b611-743cd3a5541c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# return the sum of x & y\n",
      "def sum(x,y):\n",
      " return (x)\n",
      "\n",
      "# Create a list to search\n",
      "print('M') for the number of word\n",
      "\n",
      "# Find the frequency\n",
      "sorted_idx =\n"
     ]
    }
   ],
   "source": [
    "txt = \"\"\"\\\n",
    "# return the sum of x & y\n",
    "def sum(x,y):\n",
    "\"\"\"\n",
    "print(pipe(txt, num_return_sequences=1)[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "TTk47sM187gu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TTk47sM187gu",
    "outputId": "24a44618-5260-4a1f-fa81-d8725ce2a4c8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# create some data\n",
      "x = np.random.randn(100)\n",
      "y = np.random.randn(100)\n",
      "\n",
      "# create scatter plot with x, y\n",
      "y = np.add([1)))\n",
      "y = tf.\n"
     ]
    }
   ],
   "source": [
    "txt = \"\"\"\\\n",
    "# create some data\n",
    "x = np.random.randn(100)\n",
    "y = np.random.randn(100)\n",
    "\n",
    "# create scatter plot with x, y\n",
    "\"\"\"\n",
    "print(pipe(txt, num_return_sequences=1)[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120b2530-e9cd-433c-a19c-be818d78f909",
   "metadata": {
    "id": "mr9QMI1u9Gud"
   },
   "source": [
    "---\n",
    "## Recap\n",
    "- **Training Paradigm**: The notebook introduces the two-step training paradigm for transformer models, involving pretraining on large datasets to learn general language patterns and fine-tuning on task-specific data.\n",
    "- **Dataset Preparation and Tokenization**: It details how to prepare datasets for training, including loading datasets, tokenizing text using a tokenizer from Hugging Face, and mapping tokenized data for model input.\n",
    "- **Model Training and Generation**: The notebook covers setting up the training environment, configuring the GPT-2 model, and running the training process. Additionally, it demonstrates code generation using the trained model with different temperature settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9fe897-566e-46fb-8040-3e1ff36e0c51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
