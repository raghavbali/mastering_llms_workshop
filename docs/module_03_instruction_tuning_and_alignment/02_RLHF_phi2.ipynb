{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4052da7a",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/raghavbali/mastering_llms_workshop/blob/main/docs/module_03_instruction_tuning_and_alignment/02_RLHF_phi2.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd9a764-db4c-41f7-94f2-5fb78542fcca",
   "metadata": {},
   "source": [
    "# Quick Overview of RLFH\n",
    "\n",
    "The performance of Language Models until GPT-3 was kind of amazing as-is. What the models of were essentially lacking was the aspect of **alignment**. The language generation aspect was particularly challenging due to heavy hallucinations, toxicity, etc.\n",
    "\n",
    "The authors of the seminal work **[InstructGPT](https://arxiv.org/pdf/2203.02155)** basically focussed on this aspect of aligning the language models to user's intructions (hence the name!). Their work showcased how we can further fine-tune such models in a supervised way leverage human feedback and reinforcement learning to align them.\n",
    "\n",
    "## High-Level Overview of the Setup\n",
    "\n",
    "<img src=\"../assets/03_instruct_gpt_rlhf.png\">\n",
    "\n",
    "> Source: https://arxiv.org/pdf/2203.02155"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8a0b86-baa5-49fd-b5b2-cb8a93aeacbc",
   "metadata": {},
   "source": [
    "## Key Concepts:\n",
    "\n",
    "- **Reinforcement Learning (RL)**: A machine learning paradigm where an agent learns to make decisions by performing actions and receiving _rewards or penalties_ .\n",
    "- **Human Feedback**: Evaluations provided by humans that guide the learning process, ensuring the model's outputs align with human expectations and preferences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe465e94-5116-4ada-8b4b-bcc2aaffe6d1",
   "metadata": {},
   "source": [
    "## How Does this Actually Work? Show Me Examples Please?\n",
    "\n",
    "### Standard Supervised Learning:\n",
    "- Input: \"Generate a story about a dragon and a knight.\"\n",
    "- Output: The model generates a story based on its training data.\n",
    "\n",
    "\n",
    "### Reinforcement Learning From Human Feedback:\n",
    "- Input: \"Generate a story about a dragon and a knight.\"\n",
    "- Initial Output: The model generates a story.\n",
    "- Human Feedback: A human rates the story on coherence, creativity, and engagement.\n",
    "- Adjusted Output: The model refines its story generation based on the feedback, leading to more engaging and coherent stories over time.\n",
    "\n",
    "As pointed out in the figure above, one of the ways of bringing this alignment is through:\n",
    "- Training a **reward model** using a Human labelled dataset.\n",
    "    - This dataset basically contains rank ordered responses to different inputs to the model\n",
    "- The reward model learns to predict human preferences based on the provided human feedback by assigning a score (reward) to the outputs of the language model.\n",
    "-  The output of the reward model is then used to update the policy of the language model (agent) to align with the human feedback (exploration vs exploitation)\n",
    "\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/images/trl_overview.png\">\n",
    "\n",
    "> Source: https://huggingface.co/docs/trl/en/quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0670ad0a-0feb-4893-94ef-0582aa14c0a1",
   "metadata": {},
   "source": [
    "## PPO vs DPO\n",
    "\n",
    "There are different ways of performing policy optimisation. The original work follows Proximal Policy Optimisation which requires a separate reward model to tune the Language Model. DPO or Direct Policy Optimisation directly applies updates to the language model thus removing the need for a separate reward model.\n",
    "\n",
    "> Read more about RL and KL Divergence to understand the topic better\n",
    "\n",
    "\n",
    "> The KL-divergence between the two outputs is used as an _additional reward signal_ to make sure the generated responses don’t deviate too far from the reference language model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0895576f-f530-4268-b13d-a2898c160c6d",
   "metadata": {},
   "source": [
    "# Quick Hello World Using PPO\n",
    "\n",
    "> Can we improve alignment of Phi-1.5?\n",
    "\n",
    "> Adapted from:\n",
    "> [[1](https://huggingface.co/docs/trl/en/quickstart)], [[2](https://github.com/antndlcrx/oxford-llms-workshop/blob/main/materials/seminars/day_3/8_LLMs%20alignment%20with%20RLHF.ipynb)]\n",
    "\n",
    "**NOTE**: Ensure you have high-capacity GPU available for this notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4c1c30-1627-4373-affb-6ae932062c31",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aac1de-86c7-41f6-8bcf-0871c8e7e75c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install -U trl==0.11 datasets==4.0.0 accelerate==1.10.0 peft==0.17.0 bitsandbytes==0.47.0  tensorboardX==2.6.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c056d2d1-2870-463b-b9d8-6146f9c87186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46e81e4e-3abb-492d-9c2e-0595f1b002cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0+cu121'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26a627cf-50c2-4fdc-b218-ab7ab73ec5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.11.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import trl\n",
    "trl.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af9fccb-8f74-4055-837a-290bc88d7abc",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cb50023-862f-4732-9810-847ed649492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import choices\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "from trl import PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead, create_reference_model\n",
    "from trl.core import LengthSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df2c94d-bf36-4c16-aa91-d422eed1a076",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a741d7a7-dc43-45aa-905b-c0950c90efc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input_length = 5\n",
    "text_output_length = 20\n",
    "seed = 42\n",
    "\n",
    "sentiment_pipe_kwargs = {\n",
    "    \"top_k\": None, \n",
    "    \"function_to_apply\": \"none\",\n",
    "    'return_all_scores':False\n",
    "}\n",
    "# microsoft/Phi-3-mini-4k-instruct\n",
    "ppo_config = PPOConfig(\n",
    "    model_name=\"openai-community/gpt2\",#\"microsoft/phi-2\", \n",
    "    steps=100,\n",
    "    learning_rate=1.41e-5, \n",
    "    remove_unused_columns=True,\n",
    "    log_with=\"tensorboard\",\n",
    "    project_kwargs={\"logging_dir\": \"./logs\"},\n",
    ")\n",
    "\n",
    "generation_kwargs = {\n",
    "    \"min_length\": -1,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True,\n",
    "}\n",
    "\n",
    "ALIGNED_MODEL_NAME = f\"aligned-{ppo_config.model_name.split('/')[1]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c370fbf6-9688-4ef4-8766-e818d50365e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc2de781d1044c0798f8800553a5aba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1421f780-6e7e-4a18-877b-d17d05a55857",
   "metadata": {},
   "source": [
    "## Download Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78f832e9-0109-49cd-afce-c2b7940b2081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028ea289e433471c95b66d2e37a46693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8deaba31b0f7476eb5083d9d418c4dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e69f21c0094fd29bd5731ea583b275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554cce91d9114e33b1114d2ea9e83f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bfa8c3f24e54f4bbb1024f22f6d9e33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b087048d26dd4a509f15e595c098f4f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea347154ee7c403cbf5f31897648a006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "343ae41123314630af0befb1073ba668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(\n",
    "    ppo_config.model_name,\n",
    "    cache_dir=\"/workspace/\"\n",
    ")\n",
    "# create a reference model\n",
    "ref_model = create_reference_model(model, num_shared_layers=6)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    ppo_config.model_name,\n",
    "    cache_dir=\"/workspace/\"\n",
    ")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "generation_kwargs[\"pad_token_id\"] = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d8f326a-29fb-4c71-825c-f646d1a22baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Aug 17 07:38:33 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 575.57.08              Driver Version: 575.57.08      CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A40                     On  |   00000000:56:00.0 Off |                    0 |\n",
      "|  0%   31C    P8             22W /  300W |       3MiB /  46068MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edff3ac-04d3-4834-bd78-ce71204490aa",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd06c08d-97a6-4211-9281-b9994b15eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(\n",
    "    tokenizer, dataset_name=\"imdb\", input_min_text_length=2, input_max_text_length=8\n",
    "):\n",
    "    # load imdb with datasets\n",
    "    ds = load_dataset(dataset_name, split=\"train\",cache_dir='/workspace')\n",
    "    ds = ds.rename_columns({\"text\": \"review\"})\n",
    "    ds = ds.filter(lambda x: len(x[\"review\"]) > 200, batched=False)\n",
    "\n",
    "    input_size = LengthSampler(input_min_text_length, input_max_text_length)\n",
    "\n",
    "    def tokenize(sample):\n",
    "        sample[\"input_ids\"] = tokenizer.encode(sample[\"review\"])[: input_size()]\n",
    "        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
    "        return sample\n",
    "\n",
    "    ds = ds.map(tokenize, batched=False)\n",
    "    ds.set_format(type=\"torch\")\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0de8e00-8083-4b8a-9632-53b29fdff156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3f7fd69d15a4b3f94d3b7b9b29d6f12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24895 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "dataset = prepare_dataset(tokenizer)\n",
    "\n",
    "\n",
    "def data_collator(data):\n",
    "    return dict((key, [d[key] for d in data]) for key in data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b99af4-7dcb-4bbb-a0a6-4ae052b00462",
   "metadata": {},
   "source": [
    "## Setup PPO Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ed7fe2c-202e-4f26-a0bf-f32fb28f23fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:193: FutureWarning: `PPOTrainer` is deprecated and will be removed in trl v0.12. Please use `PPOv2Trainer` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ppo_trainer = PPOTrainer(ppo_config,\n",
    "                         model,\n",
    "                         ref_model,\n",
    "                         tokenizer,\n",
    "                         dataset,\n",
    "                         data_collator=data_collator,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdc08b7b-37e5-4086-930f-5141d293580b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accelerator Device=0\n"
     ]
    }
   ],
   "source": [
    "if ppo_trainer.accelerator.num_processes == 1:\n",
    "    device = 0 if torch.cuda.is_available() else \"cpu\"  \n",
    "else:\n",
    "    device = ppo_trainer.accelerator.device\n",
    "print(f\"Accelerator Device={device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59df473a-8ef4-4075-ad99-1faf93506a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo_trainer.accelerator.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66483a3e-e7b0-4acb-b8f8-d61fc046a796",
   "metadata": {},
   "source": [
    "### Setup Reward Model and Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272f3030-2639-436a-8e76-fc9ee8c32351",
   "metadata": {},
   "source": [
    "### Reward Assignment\n",
    "\n",
    "The objective is to align our text generation model towards the alignment signal provided.\n",
    "To do so, we need to assign a corresponding reward to each output logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1715dab4-0733-430b-8575-dcff542dce9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 4.6659016609191895},\n",
       " {'label': 'POSITIVE', 'score': -3.7129852771759033}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get the Reward Model\n",
    "distilbert_tokenizer = AutoTokenizer.from_pretrained(\"lvwerra/distilbert-imdb\",eos_token='</s>')\n",
    "sentiment_pipe = pipeline(\"text-classification\")\n",
    "#, \"lvwerra/distilbert-imdb\", tokenizer=distilbert_tokenizer,device=device)\n",
    "\n",
    "# test out the pipeline\n",
    "text = \"this movie was really bad!!\"\n",
    "output = sentiment_pipe(text, **sentiment_pipe_kwargs)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6346baa6-53a9-4820-9933-f8d1d1962a5f",
   "metadata": {},
   "source": [
    "## Time to Align using RLHF : PPO\n",
    "- Get a batch of queries and prepare training input\n",
    "- Get the query responses from the policy (model to be aligned)\n",
    "- Join query and responses and tokenize for reward based on sentiment analysis\n",
    "- Optimize policy with PPO using the (query, response, reward) triplet\n",
    "- Log all the training statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "529ca163-4f12-4a6b-9cc0-df3196dfe45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bf2e88d-abb5-4527-b616-63e5e0fe406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_min_length = 10\n",
    "output_max_length = 25\n",
    "num_steps = 5\n",
    "overall_rewards = list()\n",
    "output_length_sampler = LengthSampler(output_min_length, output_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5914ba7-bc24-48d7-aa2d-e55630c553c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_kwargs[\"pad_token_id\"]= tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d93534f3-4eb3-414a-a99d-f17b3a382442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Aug 17 07:39:17 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 575.57.08              Driver Version: 575.57.08      CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A40                     On  |   00000000:56:00.0 Off |                    0 |\n",
      "|  0%   35C    P0             75W /  300W |    1927MiB /  46068MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c096ba95-3f56-4a9d-83d9-fef3132ff814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f093dd499204ce1a46ce79aa341ce50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 0.0\n",
      "ppo/returns/mean: 1.5722572803497314\n",
      "ppo/policy/advantages_mean: -5.84645860612909e-08\n",
      "---------------------------------------------------------------------------------------------------\n",
      "objective/kl: -0.002945292741060257\n",
      "ppo/returns/mean: 1.535487413406372\n",
      "ppo/policy/advantages_mean: 1.3586353375671933e-08\n",
      "---------------------------------------------------------------------------------------------------\n",
      "objective/kl: -0.05121579021215439\n",
      "ppo/returns/mean: 1.119126796722412\n",
      "ppo/policy/advantages_mean: 8.762297909470362e-08\n",
      "---------------------------------------------------------------------------------------------------\n",
      "objective/kl: 0.01759793609380722\n",
      "ppo/returns/mean: 1.6412243843078613\n",
      "ppo/policy/advantages_mean: 3.377779478341836e-08\n",
      "---------------------------------------------------------------------------------------------------\n",
      "objective/kl: 0.0692419707775116\n",
      "ppo/returns/mean: 2.6154704093933105\n",
      "ppo/policy/advantages_mean: -1.163447365115644e-07\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
    "    if epoch >= num_steps:\n",
    "        break\n",
    "\n",
    "    query_tensors = batch[\"input_ids\"]\n",
    "\n",
    "    #### Get response from gpt2\n",
    "    response_tensors = []\n",
    "    for query in query_tensors:\n",
    "        gen_len = output_length_sampler()\n",
    "        generation_kwargs[\"max_new_tokens\"] = gen_len\n",
    "        response = ppo_trainer.generate(query, **generation_kwargs)\n",
    "        response_tensors.append(response.squeeze()[-gen_len:])\n",
    "    batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in response_tensors]\n",
    "\n",
    "    #### Compute sentiment score\n",
    "    texts = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
    "    pipe_outputs = sentiment_pipe(texts, **sentiment_pipe_kwargs)\n",
    "    rewards = list()\n",
    "    for output in pipe_outputs:\n",
    "        if output[0]['score']>output[1]['score']:\n",
    "            if output[0]['label'] == 'POSITIVE':\n",
    "                rewards.append(torch.tensor(4*output[0]['score']))\n",
    "            else:\n",
    "                rewards.append(torch.tensor(0.5*output[0]['score']))\n",
    "        elif output[1]['score']>output[0]['score']:\n",
    "            if output[1]['label'] == 'POSITIVE':\n",
    "                rewards.append(torch.tensor(4*output[1]['score']))\n",
    "            else:\n",
    "                rewards.append(torch.tensor(0.5*output[0]['score']))\n",
    "\n",
    "    overall_rewards.append(rewards)\n",
    "    #PPO step\n",
    "    stats = ppo_trainer.step(query_tensors, response_tensors, rewards)\n",
    "\n",
    "    print(f'objective/kl: {stats[\"objective/kl\"]}')\n",
    "    print(f'ppo/returns/mean: {stats[\"ppo/returns/mean\"]}')\n",
    "    print(f'ppo/policy/advantages_mean: {stats[\"ppo/policy/advantages_mean\"]}')\n",
    "    print(\"-\".join(\"\" for x in range(100)))\n",
    "\n",
    "    ppo_trainer.log_stats(stats, batch, rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fc6fff-6b88-46ce-8428-640944228626",
   "metadata": {},
   "source": [
    "### Plot Reward Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "563f73f9-cbd2-4e3b-a4c9-db163d8e8bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for idx,epoch_rewards in enumerate(overall_rewards):\n",
    "    plt.hist([i.item() for i in epoch_rewards], density=True, alpha=0.3)\n",
    "plt.legend(range(10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dad9f84-64ad-4ac7-9367-afd3974f1a2c",
   "metadata": {},
   "source": [
    "### Compare Rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8eb8a23d-1c3f-4c74-b3e9-c372b1c5cb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>response (before)</th>\n",
       "      <th>response (after)</th>\n",
       "      <th>rewards (before)</th>\n",
       "      <th>rewards (after)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This really is</td>\n",
       "      <td>to tackle is whether or not the metrics are e...</td>\n",
       "      <td>director. Seems very ofroly horny in yet.</td>\n",
       "      <td>1.418013</td>\n",
       "      <td>8.177265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This film, was</td>\n",
       "      <td>employed\\n\\n\\nRecent Examples on the Web\\n\\nCh...</td>\n",
       "      <td>-1 SexualizationPostureterSlut1 and -n</td>\n",
       "      <td>1.118258</td>\n",
       "      <td>1.620377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When i first went</td>\n",
       "      <td>they pitched me last week under the knowledge...</td>\n",
       "      <td>the break through a wall or better, the racis...</td>\n",
       "      <td>1.447953</td>\n",
       "      <td>12.225261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The only aspect of this film</td>\n",
       "      <td>projects is how not to mention that it's alre...</td>\n",
       "      <td>aquin doesn't has been whether it's a our-conc...</td>\n",
       "      <td>2.179706</td>\n",
       "      <td>1.220954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THE SCREAMING SK</td>\n",
       "      <td>Harry cries out into the shadows in agony. A ...</td>\n",
       "      <td>\\n\\n\\n35\\n\\nWHAT POSSIBLE THETHROW</td>\n",
       "      <td>1.602157</td>\n",
       "      <td>1.611169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bette Midler is</td>\n",
       "      <td>on Greasy Side Of Stone and titles legends Sc...</td>\n",
       "      <td>Unix Master: AACMAINT $ MacBook | Macintosh |...</td>\n",
       "      <td>1.582586</td>\n",
       "      <td>0.983169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Firstly, this</td>\n",
       "      <td>you want to change, and\\n\\nfigures you want t...</td>\n",
       "      <td>FERENC by Usenoxia powered, a commercial telev...</td>\n",
       "      <td>10.596127</td>\n",
       "      <td>1.523673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Or at least one of the</td>\n",
       "      <td>ural and sexual statements. Parasitism is an o...</td>\n",
       "      <td>.\\n\\n\\nSo I haven't heard of spinning the dead</td>\n",
       "      <td>0.125203</td>\n",
       "      <td>1.407147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I read in the papers</td>\n",
       "      <td>the dangers from using sexual desire in a pro...</td>\n",
       "      <td>\\n19. Lady Barrett sloppily remarks that only ...</td>\n",
       "      <td>2.330472</td>\n",
       "      <td>1.469326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Don't</td>\n",
       "      <td>take it as lying. Ecclestone merely asserts t...</td>\n",
       "      <td>rely solely on your gut or Pr operator) also ...</td>\n",
       "      <td>1.631847</td>\n",
       "      <td>1.371802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>When a comedy movie boasts</td>\n",
       "      <td>, itself, to mention so much about how ludicro...</td>\n",
       "      <td>a grand total of 10 million yen, you might ev...</td>\n",
       "      <td>1.316324</td>\n",
       "      <td>6.669933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A great addition</td>\n",
       "      <td>Summary\\n\\nSummaryctl brings teams together to...</td>\n",
       "      <td>a wolf to a clearing the body also allows you...</td>\n",
       "      <td>14.248089</td>\n",
       "      <td>12.224768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Warped</td>\n",
       "      <td>EXE Avion Dead Evolution Deadlight Deadlings - R</td>\n",
       "      <td>ji brew Konoha Chapter 9 溑里ア</td>\n",
       "      <td>1.495672</td>\n",
       "      <td>0.950712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>This is one of</td>\n",
       "      <td>Robert Tomaszewski, meteorologist of the Kans...</td>\n",
       "      <td>games ever for the game. Nohrian Harry&lt;|endof...</td>\n",
       "      <td>11.722445</td>\n",
       "      <td>11.485104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Any movie that portrays the hard</td>\n",
       "      <td>, foundation,&gt; 2007 Star Wars Executives</td>\n",
       "      <td>very little in the room, although he does serve</td>\n",
       "      <td>3.804927</td>\n",
       "      <td>1.109304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>This God</td>\n",
       "      <td>for us, Crispus, possibly mortal.\\n\\nSubbonus...</td>\n",
       "      <td>to this...Maun of God with one in mind of her...</td>\n",
       "      <td>0.178939</td>\n",
       "      <td>0.502152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               query  \\\n",
       "0                     This really is   \n",
       "1                     This film, was   \n",
       "2                  When i first went   \n",
       "3       The only aspect of this film   \n",
       "4                   THE SCREAMING SK   \n",
       "5                    Bette Midler is   \n",
       "6                      Firstly, this   \n",
       "7             Or at least one of the   \n",
       "8               I read in the papers   \n",
       "9                              Don't   \n",
       "10        When a comedy movie boasts   \n",
       "11                  A great addition   \n",
       "12                            Warped   \n",
       "13                    This is one of   \n",
       "14  Any movie that portrays the hard   \n",
       "15                          This God   \n",
       "\n",
       "                                    response (before)  \\\n",
       "0    to tackle is whether or not the metrics are e...   \n",
       "1   employed\\n\\n\\nRecent Examples on the Web\\n\\nCh...   \n",
       "2    they pitched me last week under the knowledge...   \n",
       "3    projects is how not to mention that it's alre...   \n",
       "4    Harry cries out into the shadows in agony. A ...   \n",
       "5    on Greasy Side Of Stone and titles legends Sc...   \n",
       "6    you want to change, and\\n\\nfigures you want t...   \n",
       "7   ural and sexual statements. Parasitism is an o...   \n",
       "8    the dangers from using sexual desire in a pro...   \n",
       "9    take it as lying. Ecclestone merely asserts t...   \n",
       "10  , itself, to mention so much about how ludicro...   \n",
       "11  Summary\\n\\nSummaryctl brings teams together to...   \n",
       "12   EXE Avion Dead Evolution Deadlight Deadlings - R   \n",
       "13   Robert Tomaszewski, meteorologist of the Kans...   \n",
       "14           , foundation,> 2007 Star Wars Executives   \n",
       "15   for us, Crispus, possibly mortal.\\n\\nSubbonus...   \n",
       "\n",
       "                                     response (after)  rewards (before)  \\\n",
       "0           director. Seems very ofroly horny in yet.          1.418013   \n",
       "1              -1 SexualizationPostureterSlut1 and -n          1.118258   \n",
       "2    the break through a wall or better, the racis...          1.447953   \n",
       "3   aquin doesn't has been whether it's a our-conc...          2.179706   \n",
       "4                  \\n\\n\\n35\\n\\nWHAT POSSIBLE THETHROW          1.602157   \n",
       "5    Unix Master: AACMAINT $ MacBook | Macintosh |...          1.582586   \n",
       "6   FERENC by Usenoxia powered, a commercial telev...         10.596127   \n",
       "7      .\\n\\n\\nSo I haven't heard of spinning the dead          0.125203   \n",
       "8   \\n19. Lady Barrett sloppily remarks that only ...          2.330472   \n",
       "9    rely solely on your gut or Pr operator) also ...          1.631847   \n",
       "10   a grand total of 10 million yen, you might ev...          1.316324   \n",
       "11   a wolf to a clearing the body also allows you...         14.248089   \n",
       "12                       ji brew Konoha Chapter 9 溑里ア          1.495672   \n",
       "13   games ever for the game. Nohrian Harry<|endof...         11.722445   \n",
       "14    very little in the room, although he does serve          3.804927   \n",
       "15   to this...Maun of God with one in mind of her...          0.178939   \n",
       "\n",
       "    rewards (after)  \n",
       "0          8.177265  \n",
       "1          1.620377  \n",
       "2         12.225261  \n",
       "3          1.220954  \n",
       "4          1.611169  \n",
       "5          0.983169  \n",
       "6          1.523673  \n",
       "7          1.407147  \n",
       "8          1.469326  \n",
       "9          1.371802  \n",
       "10         6.669933  \n",
       "11        12.224768  \n",
       "12         0.950712  \n",
       "13        11.485104  \n",
       "14         1.109304  \n",
       "15         0.502152  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 16\n",
    "game_data = dict()\n",
    "dataset.set_format(\"pandas\")\n",
    "df_batch = dataset[:].sample(bs)\n",
    "game_data[\"query\"] = df_batch[\"query\"].tolist()\n",
    "query_tensors = df_batch[\"input_ids\"].tolist()\n",
    "\n",
    "response_tensors_ref, response_tensors = [], []\n",
    "\n",
    "#### get response from phi2 and phi2_ref\n",
    "for i in range(bs):\n",
    "    gen_len = output_length_sampler()\n",
    "    output = ref_model.generate(\n",
    "        torch.tensor(query_tensors[i]).unsqueeze(dim=0).to(device),\n",
    "        # max_new_tokens=gen_len,\n",
    "        **generation_kwargs\n",
    "    ).squeeze()[-gen_len:]\n",
    "    response_tensors_ref.append(output)\n",
    "    output = model.generate(\n",
    "        input_ids=torch.tensor(query_tensors[i]).unsqueeze(dim=0).to(device),\n",
    "        # max_new_tokens=gen_len,\n",
    "        **generation_kwargs\n",
    "    ).squeeze()[-gen_len:]\n",
    "    response_tensors.append(output)\n",
    "\n",
    "#### decode responses\n",
    "game_data[\"response (before)\"] = [\n",
    "    tokenizer.decode(response_tensors_ref[i]) for i in range(bs)\n",
    "]\n",
    "game_data[\"response (after)\"] = [\n",
    "    tokenizer.decode(response_tensors[i]) for i in range(bs)\n",
    "]\n",
    "\n",
    "#### sentiment analysis of query/response pairs before/after\n",
    "texts = [q + r for q, r in zip(game_data[\"query\"], game_data[\"response (before)\"])]\n",
    "# game_data[\"rewards (before)\"] = [\n",
    "#     output[1][\"score\"] for output in sentiment_pipe(texts, **sentiment_pipe_kwargs)\n",
    "# ]\n",
    "game_data[\"rewards (before)\"]=list()\n",
    "for output in sentiment_pipe(texts, **sentiment_pipe_kwargs):\n",
    "        if output[0]['score']>output[1]['score']:\n",
    "            if output[0]['label'] == 'POSITIVE':\n",
    "                game_data[\"rewards (before)\"].append(4*output[0]['score'])\n",
    "            else:\n",
    "                game_data[\"rewards (before)\"].append(0.5*output[0]['score'])\n",
    "        elif output[1]['score']>output[0]['score']:\n",
    "            if output[1]['label'] == 'POSITIVE':\n",
    "                game_data[\"rewards (before)\"].append(4*output[1]['score'])\n",
    "            else:\n",
    "                game_data[\"rewards (before)\"].append(0.5*output[0]['score'])\n",
    "\n",
    "texts = [q + r for q, r in zip(game_data[\"query\"], game_data[\"response (after)\"])]\n",
    "\n",
    "game_data[\"rewards (after)\"]=list()\n",
    "for output in sentiment_pipe(texts, **sentiment_pipe_kwargs):\n",
    "        if output[0]['score']>output[1]['score']:\n",
    "            if output[0]['label'] == 'POSITIVE':\n",
    "                game_data[\"rewards (after)\"].append(4*output[0]['score'])\n",
    "            else:\n",
    "                game_data[\"rewards (after)\"].append(0.5*output[0]['score'])\n",
    "        elif output[1]['score']>output[0]['score']:\n",
    "            if output[1]['label'] == 'POSITIVE':\n",
    "                game_data[\"rewards (after)\"].append(4*output[1]['score'])\n",
    "            else:\n",
    "                game_data[\"rewards (after)\"].append(0.5*output[0]['score'])\n",
    "\n",
    "\n",
    "# store results in a dataframe\n",
    "df_results = pd.DataFrame(game_data)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c96b07-71f0-4636-ab36-d505f7fc7b7a",
   "metadata": {},
   "source": [
    "### Save Aligned Model Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "645c5b46-b4e7-4071-84ed-4e14f371e7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('aligned-gpt2/tokenizer_config.json',\n",
       " 'aligned-gpt2/special_tokens_map.json',\n",
       " 'aligned-gpt2/vocab.json',\n",
       " 'aligned-gpt2/merges.txt',\n",
       " 'aligned-gpt2/added_tokens.json',\n",
       " 'aligned-gpt2/tokenizer.json')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(ALIGNED_MODEL_NAME)\n",
    "tokenizer.save_pretrained(ALIGNED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1ed0ff-125e-4441-8b79-9405bd2a9d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment if you would like to push to HF Hub\n",
    "# model.push_to_hub(ALIGNED_MODEL_NAME,commit_message=\"PPO alignment done\")\n",
    "# tokenizer.push_to_hub(ALIGNED_MODEL_NAME,commit_message=\"PPO alignment done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff932ed8-2588-4a97-aed2-b027185a629e",
   "metadata": {},
   "source": [
    "## Generate and Compare Aligned vs Non-Aligned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e389057f-53aa-4071-8dd2-d3312cbaaa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb094076-ff1e-4e71-b6f9-33b3a6e60403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aligned-phi-2'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double checking if we are still refering to same model\n",
    "# assign \"aligned-phi-2\" if directly checking results\n",
    "ALIGNED_MODEL_NAME=\"aligned-phi-2\"\n",
    "ALIGNED_MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dab01114-b221-4cde-a84d-55bf4f250460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3705edac5a924b59964cec3a96e1b6e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b14087ac2d247e4b9885e37252d75ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53eab1d0c214937b455784922f33d8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "350f14de3d4645a8bce26307674a9317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/1.15G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16bf4972cc6c415286b66bb5eb43dd0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c599be6a654545a19c57095ab37e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e93dfff8b134b23837b525351c976a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at raghavbali/aligned-phi-2 were not used when initializing PhiForCausalLM: ['v_head.summary.bias', 'v_head.summary.weight']\n",
      "- This IS expected if you are initializing PhiForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing PhiForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "202977a6c7ae4adb99977afea96c34a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:A <class 'transformers.models.phi.modeling_phi.PhiForCausalLM'> model is loaded from 'raghavbali/aligned-phi-2', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b07728af7314e28b6bf2b5d6a4a12a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b05fc303f74db9ade2183d2e874414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/1.15G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5562a93b8fb4321a9ddcbb376373db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69820a82f36643ef95188af24e7a3514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c06bd513c64a758c7e800553aa71bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a34451a5bad64066b4b4f2521b78960c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d8f69ef93d941e8841d0f47f799ab43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c755a536a6b44f5db294466c3c5e5493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hub_model = AutoModelForCausalLMWithValueHead.from_pretrained(f'raghavbali/{ALIGNED_MODEL_NAME}',\n",
    "                                                              cache_dir=\"/workspace/\").to(device)\n",
    "# create a reference model\n",
    "hub_tokenizer = AutoTokenizer.from_pretrained(f'raghavbali/{ALIGNED_MODEL_NAME}',\n",
    "                                              cache_dir=\"/workspace/\")\n",
    "\n",
    "hub_tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8fd2f48-1147-4bb4-95f0-6fc2342a2257",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    \"If I have to review this movie, I would\",\n",
    "    \"The actors in this movie\",\n",
    "    \"The makers of this movie\",\n",
    "    \"I went to this movie for\",\n",
    "    \"The thing about this movie\",\n",
    "    \"Here are my 2 cents on the movie\",\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2bb1c4e6-3a0c-4f0c-9649-e701d00591b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----ALIGNED-MODEL ----\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "If I have to review this movie, I would suggest the following to the directors, producers and exhibitors:\n",
       "A good movie is always a combination of the best elements of"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- NON-ALIGNEDD-MODEL ----\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "If I have to review this movie, I would be going for the latter. I just found out that after all, I'm really not that into this. I'm not"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- END ----\n",
      "----ALIGNED-MODEL ----\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The actors in this movie are really amazing. There's John Vickers, who plays the main character Richard, and Jean-Marie Amalberti"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- NON-ALIGNEDD-MODEL ----\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The actors in this movie are really important for the characters and the story of this movie. And this is the way it is with this film and this"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- END ----\n",
      "----ALIGNED-MODEL ----\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The makers of this movie have done a wonderful job in bringing this story to life. I hope you all get a chance to watch it and enjoy it"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- NON-ALIGNEDD-MODEL ----\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The makers of this movie, and the actors who have worked with him, have been a lot of fun to work with. One of the things I"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- END ----\n",
      "----ALIGNED-MODEL ----\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "I went to this movie for the first time, and it was great to see the story come to life on the big screen. The performances were amazing,"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- NON-ALIGNEDD-MODEL ----\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "I went to this movie for the first time in my life, and I was very happy. It was not a great feeling. I guess it was a"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- END ----\n",
      "----ALIGNED-MODEL ----\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The thing about this movie is it shows us how some people were very proud of being from a certain place and how some people didn't like it."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- NON-ALIGNEDD-MODEL ----\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The thing about this movie is that it's very, very, very different than the movies you've seen in Hollywood before. You know, we've"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- END ----\n",
      "----ALIGNED-MODEL ----\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Here are my 2 cents on the movie.\n",
       "The main idea of the movie is how to get the most out of your life. To make the most money,"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- NON-ALIGNEDD-MODEL ----\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Here are my 2 cents on the movie:\n",
       "\n",
       "2/2\n",
       "\n",
       "If your story has had a lot of success or you've managed to get a lot"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- END ----\n"
     ]
    }
   ],
   "source": [
    "for review in reviews:\n",
    "    inputs = hub_tokenizer(review, return_tensors=\"pt\", return_token_type_ids=False).to(device)\n",
    "    print(\"----ALIGNED-MODEL ----\")\n",
    "    outputs = hub_model.generate(**inputs,max_new_tokens=25,temperature=0.8,do_sample=True)\n",
    "    display(Markdown((tokenizer.decode(outputs[0], skip_special_tokens=True))))\n",
    "    print(\"---- NON-ALIGNEDD-MODEL ----\")\n",
    "    outputs = ref_model.generate(**inputs, max_new_tokens=25,temperature=0.8,do_sample=True)\n",
    "    display(Markdown((tokenizer.decode(outputs[0], skip_special_tokens=True))))\n",
    "    print(\"---- END ----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9734efdf-4b6d-48ba-82f7-96d376a84a46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
